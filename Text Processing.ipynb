{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While text processing a neural network doesnt accept input as a string (Neural Network accepts  tensors).\n",
    "Embedding layer is a dictionary that maps integer indices which stand for specific words to dense vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer initialization\n",
    "embedding_layer = Embedding(1000, 64) #The Embedding layer takes at least two arguments: (The number of possibe tokens, The dimentionality of embegings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer takes as input a 2D tensor of integers, of shape (samples,sequence_length), where each entry is a sequence of integers. \n",
    "\n",
    "It can embed sequences of variable lengths:\n",
    "for instance, you could feed into the Embedding layer in the previous example batches with shapes (32, 10) (batch of 32 sequences of length 10) or (64, 15) (batch of 64 sequences of length 15).\n",
    "\n",
    "All sequences in a batch must have the same length, though (because you need to pack them into a single tensor),\n",
    "so sequences that are shorter than others should be padded with zeros, and sequences that are longer should be truncated.\n",
    "\n",
    "This layer returns a 3D floating-point tensor of shape (samples, sequence_length, embedding_dimensionality). \n",
    "\n",
    "Such a 3D tensor can then be processed by an RNN layer or a 1D convolution layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING ON IMDB DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "max_features = 10000\n",
    "max_len = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Type, Shape and Data itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1028, 1028, 26, 32, 1629, 1179, 1554, 2073, 39, 6, 2, 7, 2834, 12, 4916, 186, 38, 86, 7, 32, 14, 9, 6, 3143, 863, 15, 2856, 77, 2, 73, 6, 5482, 185, 5155, 37, 3418, 56, 9229, 5, 1496, 32, 4, 539, 37, 3810, 4, 609, 46, 7, 90, 54, 29, 16, 11, 4715, 312, 191, 135, 25, 69, 164, 8, 157, 19, 21, 14, 22, 271, 143, 4, 172, 7094, 17, 32, 4, 85, 1136, 7416, 285, 39, 4, 603, 8, 4, 370, 2445, 1741, 178, 8, 5709, 618, 54, 6, 2556, 8036, 9, 582, 5, 618, 54, 4, 455, 80, 3459, 75, 124, 4, 6481, 34, 150, 134, 379, 1179, 102, 3655, 4, 3059, 2, 53, 5, 53, 34, 4, 786, 387, 72, 942, 25, 142, 37, 11, 68, 208, 330, 9, 170, 8, 866, 6, 464, 7, 9130, 11, 6, 465, 4734, 2, 11, 4, 655, 7, 4, 314, 5, 43, 866, 41, 46, 7, 4, 1336, 137, 442, 32, 584, 5, 3391, 34, 5512, 127, 15, 97, 101, 1543, 281, 33, 32, 10, 10, 6076, 9, 64, 2036, 3972, 31, 52, 324, 2290, 4, 2, 7, 7177, 2, 109, 59, 214, 2605, 1004, 6, 3073, 5, 4, 455, 2, 33, 41, 19, 6, 5486, 225, 49, 52, 690, 11, 4, 816, 587, 31, 646, 1406, 34, 9303, 4, 228, 374, 9, 3887, 11, 4, 318, 944, 2424, 23, 4, 288, 10, 10, 60, 4, 116, 9, 1501, 33, 118, 4, 156, 32, 1666, 143, 68, 555, 7, 265, 628, 2, 9, 400, 9624, 60, 11, 27, 1146, 17, 4, 425, 109, 23, 2344, 7177, 4865, 9, 6, 478, 524, 151, 5, 59, 941, 6, 2, 469, 4, 20, 10, 10, 6076, 9, 43, 40, 1390, 535, 1948, 4035, 2441, 954, 5, 209, 6, 52, 2337, 11, 1682, 92, 60, 1414, 10, 10, 61, 603, 470, 46, 7, 158]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 2D tensor of shape (samples, maxlen)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2441  954    5  209    6   52 2337   11 1682   92   60 1414   10   10\n",
      "   61  603  470   46    7  158]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[3000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 20, 9, 44, 6, 604, 7, 372, 382, 24, 7, 4, 4082, 2, 37, 26, 5576, 8, 6, 392, 2, 8, 193, 120, 6, 1033, 2, 2, 4862, 121, 36, 1347, 8, 270, 56, 2022, 725, 4791, 11, 6, 4006, 543, 36, 169, 57, 31, 80, 140, 50, 60, 151, 94, 64, 1119, 2064, 245, 38, 36, 1135, 54, 36, 79, 50, 36, 169, 50, 26, 57, 1340, 21, 6, 52, 1166, 7, 84, 37, 28, 623, 120, 361, 7, 4, 2, 5, 2171, 56, 6, 392, 543, 4006, 36, 515, 169, 15, 142, 218, 208, 133, 5, 2, 2, 2, 4740, 17, 4, 5751, 683, 12, 9, 11, 49, 622, 1113, 10, 10, 247, 74, 140, 83, 4, 114, 347, 13, 80, 97, 49, 795, 44, 183, 13, 1925, 44, 4, 20, 86, 125, 4, 116, 9, 55, 1035, 64, 6, 171, 7, 4, 84, 306, 8, 30, 147, 195, 8, 264, 11, 61, 86, 151, 16, 338, 116, 21, 33, 4, 130, 13, 296, 49, 7, 4, 2, 5, 134, 172, 84, 877, 1239, 38, 61, 64, 197, 317, 9, 14, 9, 89, 4, 167, 473, 12, 23, 350, 7, 4, 78, 116, 13, 28, 6, 87, 439, 121, 4, 84, 92, 4027, 208, 8, 6, 348, 270, 7, 2331, 193, 18, 463, 57, 31, 62, 193, 98, 8, 2, 2, 18, 101, 1866, 60, 151, 94, 64, 1119, 2064, 245, 246, 54, 75, 3854, 33, 4, 2, 75, 169, 12, 9, 73, 2, 34, 6, 542, 3895, 7, 84, 32, 7, 937, 215, 79, 9786, 39, 49, 31, 24, 8, 760, 4738, 525, 12, 9, 424, 8, 193, 273, 11, 246, 75, 70, 67, 4, 2, 519, 47, 5318, 2690, 36, 713, 23, 33, 222, 5, 6, 2, 7515, 15, 9, 33, 222, 1088, 153, 303, 24, 31, 7, 4, 831, 405, 7, 38, 1063, 33, 15, 58, 50, 26, 82, 1370, 121, 25, 70, 67, 2, 2, 5, 279, 6, 519, 33, 31, 213, 161, 181, 8, 1414, 8, 140, 145, 5, 168, 5, 85, 2, 5278, 48, 36, 69, 1477, 4, 2269, 7, 4, 182, 36, 93, 5, 387, 4, 156, 30, 156, 12, 238, 28, 1840, 6, 470, 39, 72, 305, 7, 4, 241, 13, 520, 12, 5, 36, 2, 12, 44, 470, 53, 211, 12, 238, 28, 224, 60, 128]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 2D tensor of shape (samples, maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7   4 241  13 520  12   5  36   2  12  44 470  53 211  12 238  28 224\n",
      "  60 128]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test[3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(10000, 8, input_length=max_len))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tajr\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 4s 203us/step - loss: 0.6715 - acc: 0.6173 - val_loss: 0.6256 - val_acc: 0.6938\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.5488 - acc: 0.7497 - val_loss: 0.5308 - val_acc: 0.7270\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 0.4641 - acc: 0.7885 - val_loss: 0.5038 - val_acc: 0.7420\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.4219 - acc: 0.8097 - val_loss: 0.4988 - val_acc: 0.7508\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 126us/step - loss: 0.3921 - acc: 0.8270 - val_loss: 0.4973 - val_acc: 0.7550\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.3673 - acc: 0.8407 - val_loss: 0.5040 - val_acc: 0.7532\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.3451 - acc: 0.8514 - val_loss: 0.5078 - val_acc: 0.7492\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 127us/step - loss: 0.3247 - acc: 0.8633 - val_loss: 0.5149 - val_acc: 0.7450\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 121us/step - loss: 0.3059 - acc: 0.8737 - val_loss: 0.5232 - val_acc: 0.7430\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 125us/step - loss: 0.2872 - acc: 0.8835 - val_loss: 0.5332 - val_acc: 0.7400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Note about this section is that I didn't get through it smoothly, I recommend repetition. For now keep going futher. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
