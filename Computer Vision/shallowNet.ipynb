{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary for building architecture\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "\n",
    "# Necessary for classification\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Necessary to dataset preprocessing\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "# from imagelab.preprocessing import ImageToArrayPreprocessor\n",
    "# from imagelab.preprocessing import ImageResizePreprocessor\n",
    "# from imagelab.datasets import DatasetLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageLab Preprocessing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image To Array Preprocessor\n",
    "class ImageToArrayPreprocessor:\n",
    "    # Constructor\n",
    "    def __init__(self, dataFormat=None):\n",
    "        # Store the data format\n",
    "        self.dataFormat = dataFormat\n",
    "        \n",
    "    # Data format processor\n",
    "    def process(self, image):\n",
    "        # Process data using keras img_to_array method\n",
    "        return img_to_array(image, data_format=self.dataFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Resize Preprocessor\n",
    "class ImageResizePreprocessor:\n",
    "    # Constructor\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "        # Store the target image width, height and interpolation method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "    \n",
    "    # Size Processor\n",
    "    def process(self, image):\n",
    "        # Resize image while ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageLab Datasets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "class DatasetLoader:\n",
    "    # Constructor\n",
    "    def __init__(self, preprocessors=None):\n",
    "        # Store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        # Initialize preprocessors as a list of its None\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "    \n",
    "    # Loader\n",
    "    def load(self, imagePaths, verbose=1):\n",
    "        # Initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # Loop over the input image\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # Load image and extract the class labels\n",
    "            image = cv2.imread(imagePath)\n",
    "            image_label = imagePath.split(os.path.sep)[-1]\n",
    "            label = image_label[:3]\n",
    "            \n",
    "            # Check if preprocessor is not None\n",
    "            if self.preprocessors is not None:\n",
    "                # Loop over the preprocessors and apply each to the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.process(image)\n",
    "            \n",
    "            # Treat preprocessed image as a feature vector by updating the data list and the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # Show an update every verbose image\n",
    "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                print('[INFO] processed {}/{}'.format(i + 1, len(imagePaths)))\n",
    "        \n",
    "        # Return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 33,665\n",
      "Trainable params: 33,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class shallowNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model and input shape to be channel_last\n",
    "        model = models.Sequential()\n",
    "        input_shape = (width, height, depth)\n",
    "        \n",
    "        # if we are using channel_first, update the input_shape accordingly\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (depth, width, height)\n",
    "        \n",
    "        # Define a models\n",
    "        model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "        \n",
    "        # return constructed network\n",
    "        return model\n",
    "\n",
    "# Build a model that accept (32 x 32 x3) rgb image organized in 10 classes\n",
    "model = shallowNet.build(32, 32, 3, 2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/CatDog/SmallDataset'\n",
    "\n",
    "# Loading Training Cats\n",
    "train_cats_base_dir = os.path.join(base_dir, 'train/cats')\n",
    "train_cats_images = list(paths.list_images(train_cats_base_dir))\n",
    "\n",
    "# Loading Training Dogs\n",
    "train_dogs_base_dir = os.path.join(base_dir, 'train/dogs')\n",
    "train_dogs_images = list(paths.list_images(train_dogs_base_dir))\n",
    "\n",
    "# Group Training Cats and Dogs\n",
    "train_images_path = train_cats_images\n",
    "\n",
    "for path in train_dogs_images:\n",
    "    train_images_path.append(path)\n",
    "\n",
    "# Loading Validation Cats\n",
    "validation_cats_base_dir = os.path.join(base_dir, 'validation/cats')\n",
    "validation_cats_images = list(paths.list_images(validation_cats_base_dir))\n",
    "\n",
    "# Loading Validation Dogs\n",
    "validation_dogs_base_dir = os.path.join(base_dir, 'validation/dogs')\n",
    "validation_dogs_images = list(paths.list_images(validation_dogs_base_dir))\n",
    "\n",
    "# Group Validation Cats and Dogs\n",
    "validation_images_path = validation_cats_images\n",
    "\n",
    "for path in validation_dogs_images:\n",
    "    validation_images_path.append(path)\n",
    "\n",
    "# Loading Test Cats\n",
    "test_cats_base_dir = os.path.join(base_dir, 'test/cats')\n",
    "test_cats_images = list(paths.list_images(test_cats_base_dir))\n",
    "\n",
    "# Loading Test Dogs\n",
    "test_dogs_base_dir = os.path.join(base_dir, 'test/dogs')\n",
    "test_dogs_images = list(paths.list_images(test_dogs_base_dir))\n",
    "\n",
    "# Grouping Test Cats and Dogs\n",
    "test_images_path = test_cats_images\n",
    "\n",
    "for path in test_dogs_images:\n",
    "    test_images_path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Train Image Path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/CatDog/SmallDataset\\\\train/cats\\\\cat.0.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First Train Image Path\")\n",
    "train_images_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Validation Image Path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/CatDog/SmallDataset\\\\validation/cats\\\\cat.1000.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First Validation Image Path\")\n",
    "validation_images_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Test Image Path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/CatDog/SmallDataset\\\\test/cats\\\\cat.1500.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First Test Image Path\")\n",
    "test_images_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.999.jpg\n"
     ]
    }
   ],
   "source": [
    "train_image_label = train_images_path[1999].split(os.path.sep)[-1]\n",
    "print(train_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "train_label = train_image_label[:3]\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preprocessing\n",
    "\n",
    "# Initialize the Image Preprocessor\n",
    "irp = ImageResizePreprocessor(32, 32)\n",
    "i2a = ImageToArrayPreprocessor()\n",
    "\n",
    "# Label Encoder\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Load Data and apply image the scale the pixels intensities to the range [0, 1]\n",
    "dl = DatasetLoader(preprocessors=[irp, i2a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/2000\n",
      "[INFO] processed 1000/2000\n",
      "[INFO] processed 1500/2000\n",
      "[INFO] processed 2000/2000\n"
     ]
    }
   ],
   "source": [
    "# Train Data and Labels\n",
    "(train_data, train_labels) = dl.load(train_images_path, verbose=500)\n",
    "train_data = train_data.astype('float') / 255.0\n",
    "train_labels = lb.fit_transform(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1000\n",
      "[INFO] processed 1000/1000\n"
     ]
    }
   ],
   "source": [
    "# Validation Data and Labels\n",
    "(validation_data, validation_labels) = dl.load(validation_images_path, verbose=500)\n",
    "validation_data.astype('float') / 255.0\n",
    "validation_labels = lb.fit_transform(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1000\n",
      "[INFO] processed 1000/1000\n"
     ]
    }
   ],
   "source": [
    "# Test Data and Labels\n",
    "(test_data, test_labels) = dl.load(test_images_path, verbose=500)\n",
    "test_data.astype('float') / 255.0\n",
    "test_labels = lb.fit_transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 7.6666 - acc: 0.5000 - val_loss: 7.6246 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "1824/2000 [==========================>...] - ETA: 0s - loss: 7.6330 - acc: 0.5022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-798c87533634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0;32m    185\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Deep_Learning\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(train_data, train_labels, epochs=100, batch_size=32, verbose=1, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
