{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import h5py as h5\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/computervision/CatDog/All/'\n",
    "processing_widgets = ['Processing Images: ', progressbar.Percentage(),' ', progressbar.Bar(),' ', progressbar.ETA()]\n",
    "loading_widgets = ['Loading Images: ', progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    # constructor\n",
    "    def __init__(self, width, height, inter=cv2.INTER_AREA, dataFormat=None):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        self.dataFormat = dataFormat\n",
    "        \n",
    "    \n",
    "    # path getter\n",
    "    def get_images_path(self, images_dir):\n",
    "        path =list(paths.list_images(images_dir)) \n",
    "        return path\n",
    "    \n",
    "    \n",
    "    # images loader\n",
    "    def load_images_labels(self, images_path):\n",
    "        images_data = list()\n",
    "        labels = list()\n",
    "        \n",
    "        # start a progress bar\n",
    "        prog_load = progressbar.ProgressBar(maxval=len(images_path), widgets=loading_widgets).start()\n",
    "        \n",
    "        # load, preprocess images and extract labels\n",
    "        for (i, path) in enumerate(images_path):\n",
    "            single_image = list()\n",
    "            image = cv2.imread(path)\n",
    "            image = self.resize(image)\n",
    "            image = self.img2array(image)\n",
    "            \n",
    "            images_data.append(image)\n",
    "#             single_image.append(image)\n",
    "#             single_image = np.array(single_image)\n",
    "#             single_image = single_image.astype('float') / 255.0\n",
    "            \n",
    "#             if len(images_data) == 0:\n",
    "#                 images_data = single_image\n",
    "#             else:\n",
    "#                 images_data = np.append(images_data, single_image, axis=0)\n",
    "            \n",
    "            #get labels\n",
    "            image_file = path.split('/')[-1]\n",
    "            label = image_file.split('.')[0]\n",
    "            labels.append(label)\n",
    "            \n",
    "            # update progress bar\n",
    "            prog_load.update(i)\n",
    "        \n",
    "        # convert images list to numpy array\n",
    "        images_data = np.array(images_data).astype('float') / 255\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # scale pixels intensity\n",
    "#         images_data = images_data.astype('float') / 255\n",
    "        \n",
    "        # finish progress bar\n",
    "        prog_load.finish()\n",
    "        \n",
    "        return (images_data, labels)\n",
    "    \n",
    "    # resize image\n",
    "    def resize(self, image):\n",
    "        # grab (height,width) and initialize deltas\n",
    "        (h, w) = image.shape[:2]\n",
    "        dH = 0\n",
    "        dW = 0\n",
    "        \n",
    "        # resize\n",
    "        if w < h:\n",
    "            image = imutils.resize(image, width=self.width, inter=self.inter)\n",
    "            dH = int((image.shape[0] - self.height) / 2.0)\n",
    "        else:\n",
    "            image = imutils.resize(image, height=self.height, inter=self.inter)\n",
    "            dW = int((image.shape[1] - self.width) / 2.0)\n",
    "        \n",
    "        # Cropping\n",
    "        (h, w) = image.shape[:2]\n",
    "        image = image[dH:h - dH, dW:w - dW]\n",
    "        \n",
    "        #resize back to a given spatial dimension\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)\n",
    "    \n",
    "    #convert image to array\n",
    "    def img2array(self, image):\n",
    "        return img_to_array(image, data_format=self.dataFormat)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(width=224, height=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = shuffle(preprocessor.get_images_path(images_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images: 100% |##########################################| Time: 0:08:10\n"
     ]
    }
   ],
   "source": [
    "(images, targets) = preprocessor.load_images_labels(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'cat', 'dog', ..., 'cat', 'cat', 'cat'], dtype='<U3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog'], dtype='<U3')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = lb.classes_\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWriter:\n",
    "    # constructor\n",
    "    def __init__(self, data_dim, labels_dim, outputFile, dataKey='Features', buffer_size=1000):\n",
    "        \n",
    "        # check to see if dataset file exists \n",
    "        if os.path.exists(outputFile):\n",
    "            raise ValueError('The supplied file name already exists, choose different name.')\n",
    "            \n",
    "        # open the HDF5 database for writing\n",
    "        self.database = h5.File(outputFile, 'w')\n",
    "        \n",
    "        # create a data and labels container\n",
    "        self.data = self.database.create_dataset(dataKey, data_dim, dtype='float')\n",
    "        self.labels = self.database.create_dataset('Labels', labels_dim, dtype='int')\n",
    "        \n",
    "        # initialize buffer and store the buffer_size along with index\n",
    "        self.buffer = {'data': [], 'labels': []}\n",
    "        self.buffer_size = buffer_size\n",
    "        self.index = 0\n",
    "    \n",
    "    # add data to a dataset\n",
    "    def add(self, data, labels):\n",
    "        self.buffer['data'].extend(data)\n",
    "        self.buffer['labels'].extend(labels)\n",
    "        \n",
    "        # flush buffer to dataset if the buffer size is reach\n",
    "        if len(self.buffer['data']) >= self.buffer_size:\n",
    "            self.flush()\n",
    "    \n",
    "    # flush buffer to HDF5 dataset created\n",
    "    def flush(self):\n",
    "        # initialize count\n",
    "        count = self.index + len(self.buffer['data'])\n",
    "\n",
    "        # store data\n",
    "        self.data[self.index:count] = self.buffer['data']\n",
    "        self.labels[self.index:count] = self.buffer['labels']\n",
    "\n",
    "        # update index\n",
    "        self.index = count\n",
    "\n",
    "        # refresh buffer\n",
    "        self.buffer = {'data': [], 'labels': []}\n",
    "    \n",
    "    # deal with class labels\n",
    "    def storeClassLabels(self, classLabels):\n",
    "        data_type = h5.special_dtype(vlen=str)\n",
    "        \n",
    "        # create labels container and store label names.\n",
    "        label_names = self.database.create_dataset('label_names', (len(classLabels), ), dtype=data_type)\n",
    "        label_names[:] = classLabels\n",
    "    \n",
    "    # close a database\n",
    "    def close(self):\n",
    "        # store remaining data\n",
    "        if len(self.buffer['data']) > 0:\n",
    "            self.flush()\n",
    "        \n",
    "        # closing\n",
    "        self.database.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimension = (len(images), 512 * 7 * 7)\n",
    "labels_dimension = labels.shape\n",
    "batch_size = 32\n",
    "\n",
    "feature_file = 'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/computervision/HDF5/cat_dog_8k.hdf5'\n",
    "\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "dataset = DatasetWriter(data_dimension, labels_dimension, feature_file, dataKey='Features', buffer_size=1000)\n",
    "\n",
    "extraction_widgets = ['Extracting Feature: ', progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store class labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.storeClassLabels(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Feature: 100% |######################################| Time: 0:06:47\n"
     ]
    }
   ],
   "source": [
    "# initialize progress bar\n",
    "prog_extract = progressbar.ProgressBar(maxval=len(images), widgets=extraction_widgets).start()\n",
    "\n",
    "# loop in batches\n",
    "for i in np.arange(0, len(images), batch_size):\n",
    "    # initialize batch images and labels\n",
    "    batch_images = images[i:i + batch_size]\n",
    "    batch_labels = labels[i:i + batch_size]\n",
    "    \n",
    "    # predict possible features (extract features)\n",
    "    features = model.predict(batch_images, batch_size=batch_size)\n",
    "    \n",
    "    # flatten features for classifiers\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "    \n",
    "    # store data and labels in an HDF5 dataset\n",
    "    dataset.add(features, batch_labels)\n",
    "    prog_extract.update(i)\n",
    "\n",
    "dataset.close()\n",
    "prog_extract.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
