{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global\n",
    "Base_dir = 'C:/Users/Tajr/Desktop/Data/RadonPlus/RadonTechnology/Dev/Deep Learning/Datasets/CatDog/'\n",
    "lb = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Extractor\n",
    "def extract_labels(img_dir, img_path_list):\n",
    "    img_labels = []\n",
    "    img_dir_len = len(img_dir)\n",
    "    \n",
    "    for img_path in img_path_list:\n",
    "        img_label = img_path[img_dir_len:]\n",
    "        img_labels.append(img_label[:3])\n",
    "    \n",
    "    return img_labels\n",
    "\n",
    "# Group Two Lists\n",
    "def group_data(list_one, list_two):\n",
    "    joint_list = list_one\n",
    "    \n",
    "    for item in list_two:\n",
    "        joint_list.append(item)\n",
    "    \n",
    "    return joint_list\n",
    "\n",
    "# Resizer (ignore image aspect ratio)\n",
    "def img_resizer(img, width, height, interpolation):\n",
    "    inter = interpolation\n",
    "    return cv2.resize(img, (width, height), inter)\n",
    "\n",
    "# Image to array preprocessor\n",
    "def img2array(img, dataFormat=None):\n",
    "    return img_to_array(img, data_format=dataFormat)\n",
    "\n",
    "# Image Loader\n",
    "def load_img(img_paths, verbose=1):\n",
    "    data = []\n",
    "    \n",
    "    for (i, img_path) in enumerate(img_paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Resize Preprocessor\n",
    "        interpolation = cv2.INTER_AREA\n",
    "        img = img_resizer(img, 32, 32, interpolation)\n",
    "        \n",
    "        # Image To Array Preprocessor\n",
    "        img = img2array(img)\n",
    "        \n",
    "        data.append(img)\n",
    "        \n",
    "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "            print('[INFO] processed {} / {}'.format((i + 1), len(img_paths)))\n",
    "        \n",
    "        return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "cat   |   [0]\n",
      "cat   |   [0]\n",
      "dog   |   [1]\n",
      "cat   |   [0]\n",
      "cat   |   [0]\n",
      "\n",
      "Train data type:  <class 'numpy.ndarray'>\n",
      "Train labels type:  <class 'numpy.ndarray'>\n",
      "Train data shape:  (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cats\n",
    "train_cats_dir = os.path.join(Base_dir, 'train/cats/')\n",
    "train_cats_images = list(paths.list_images(train_cats_dir))\n",
    "train_cats_labels = extract_labels(train_cats_dir, train_cats_images)\n",
    "\n",
    "\n",
    "# Dogs\n",
    "train_dogs_dir = os.path.join(Base_dir, 'train/dogs/')\n",
    "train_dogs_images = list(paths.list_images(train_dogs_dir))\n",
    "train_dogs_labels = extract_labels(train_dogs_dir, train_dogs_images)\n",
    "\n",
    "\n",
    "# Group cats and dogs (data, labels)\n",
    "train_data_paths = group_data(train_cats_images, train_dogs_images)\n",
    "train_labels = group_data(train_cats_labels, train_dogs_labels)\n",
    "\n",
    "# Shuffle\n",
    "(train_data_paths, train_labels) = shuffle(train_data_paths, train_labels)\n",
    "\n",
    "# Train data\n",
    "train_data = load_img(train_data_paths, verbose=500)\n",
    "train_data = train_data.astype('float') / 255.0\n",
    "\n",
    "# Convert labels to numpy array\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Binarize labels\n",
    "labels = train_labels\n",
    "train_labels = lb.fit_transform(train_labels)\n",
    "\n",
    "for i in np.arange(0, 10):\n",
    "    print(labels[i], \"  |  \", train_labels[i])\n",
    "    \n",
    "# Check Ups\n",
    "print()\n",
    "print(\"Train data type: \", type(train_data))\n",
    "print(\"Train labels type: \", type(train_labels))\n",
    "print(\"Train data shape: \", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat  |   [0]\n",
      "cat  |   [0]\n",
      "dog  |   [1]\n",
      "dog  |   [1]\n",
      "dog  |   [1]\n",
      "cat  |   [0]\n",
      "cat  |   [0]\n",
      "dog  |   [1]\n",
      "cat  |   [0]\n",
      "dog  |   [1]\n",
      "\n",
      "Validation data type:  <class 'numpy.ndarray'>\n",
      "Validation labels type:  <class 'numpy.ndarray'>\n",
      "Validation data shape:  (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cats\n",
    "validation_cats_dir = os.path.join(Base_dir, 'validation/cats/')\n",
    "validation_cats_images = list(paths.list_images(validation_cats_dir))\n",
    "validation_cats_labels = extract_labels(validation_cats_dir, validation_cats_images)\n",
    "\n",
    "# Dogs\n",
    "validation_dogs_dir = os.path.join(Base_dir, 'validation/dogs/')\n",
    "validation_dogs_images = list(paths.list_images(validation_dogs_dir))\n",
    "validation_dogs_labels = extract_labels(validation_dogs_dir, validation_dogs_images)\n",
    "\n",
    "# Group Validation\n",
    "validation_data_paths = group_data(validation_cats_images, validation_dogs_images)\n",
    "validation_labels = group_data(validation_cats_labels, validation_dogs_labels)\n",
    "\n",
    "# Shuffle\n",
    "(validation_data_paths, validation_labels) = shuffle(validation_data_paths, validation_labels)\n",
    "\n",
    "# Validation data\n",
    "validation_data = load_img(validation_data_paths, verbose=500)\n",
    "validation_data = validation_data.astype('float') / 255.0\n",
    "\n",
    "# Convert labels to numpy array\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "# Binerize labels\n",
    "labels = validation_labels\n",
    "validation_labels = lb.fit_transform(validation_labels)\n",
    "\n",
    "for i in np.arange(0, 10):\n",
    "    print(labels[i], \" |  \", validation_labels[i])\n",
    "\n",
    "# Check Ups\n",
    "print()\n",
    "print(\"Validation data type: \", type(validation_data))\n",
    "print(\"Validation labels type: \", type(validation_labels))\n",
    "print(\"Validation data shape: \", validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "cat   |   [0]\n",
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "dog   |   [1]\n",
      "cat   |   [0]\n",
      "cat   |   [0]\n",
      "cat   |   [0]\n",
      "dog   |   [1]\n",
      "\n",
      "Test data type:  <class 'numpy.ndarray'>\n",
      "Test labels type:  <class 'numpy.ndarray'>\n",
      "Test data shape:  (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Cats\n",
    "test_cats_dir = os.path.join(Base_dir, 'test/cats/')\n",
    "test_cats_images = list(paths.list_images(test_cats_dir))\n",
    "test_cats_labels = extract_labels(test_cats_dir, test_cats_images)\n",
    "\n",
    "# Dogs\n",
    "test_dogs_dir = os.path.join(Base_dir, 'test/dogs/')\n",
    "test_dogs_images = list(paths.list_images(test_dogs_dir))\n",
    "test_dogs_labels = extract_labels(test_dogs_dir, test_dogs_images)\n",
    "\n",
    "# Group Test\n",
    "test_data_paths = group_data(test_cats_images, test_dogs_images)\n",
    "test_labels = group_data(test_cats_labels, test_dogs_labels)\n",
    "\n",
    "# Shuffle\n",
    "(test_data_paths, test_labels) = shuffle(test_data_paths, test_labels, random_state=0)\n",
    "\n",
    "# Test data\n",
    "test_data = load_img(test_data_paths, verbose=500)\n",
    "test_data = test_data.astype('float') / 255.0\n",
    "\n",
    "# Convert labels to numpy array\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Binarize labels\n",
    "labels = test_labels\n",
    "test_labels = lb.fit_transform(test_labels)\n",
    "\n",
    "for i in np.arange(0, 10):\n",
    "    print(labels[i], \"  |  \", test_labels[i])\n",
    "    \n",
    "# Check Ups\n",
    "print()\n",
    "print(\"Test data type: \", type(test_data))\n",
    "print(\"Test labels type: \", type(test_labels))\n",
    "print(\"Test data shape: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
